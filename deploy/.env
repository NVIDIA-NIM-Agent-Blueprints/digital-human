# Authentication for downloadable NIMs
NGC_API_KEY=${NGC_API_KEY}

# Path where models will be stored and cached for NIM's
# NOTE: This should be an absolute path and not relative path
MODEL_DIRECTORY=${PWD}

# Set the model to be used for LLM inference 
# 'meta/llama3-8b-instruct' for Llama3-8b-instruct or 'lora-nemo-fw' to apply the LoRA weights 
LLM_MODEL_NAME=meta/llama3-8b-instruct

# Directory where all the served LoRAs are stored for a particular model in the NIM container
NIM_PEFT_SOURCE=/home/nvs/loras
NIM_PEFT_REFRESH_INTERVAL=3600 # will check NIM_PEFT_SOURCE for newly added models every hour

# Directory where LoRA weights are organized locally
LOCAL_PEFT_DIRECTORY=../customize/loras